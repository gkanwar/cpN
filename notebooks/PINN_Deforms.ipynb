{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327d87d5-8444-4cc1-a312-dffc0af792fa",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35669e9-4dc2-4cff-87a0-e989bc97d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis as al\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6ab65-04a1-4537-8155-e3ee05662018",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cpu')\n",
    "train_device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87e35e-4664-40b7-9b3f-03bb22da0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1e5f2-4cc4-4096-b56e-299c1c241c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = np.fromfile('../heatbath_cpp/data/cpn_b4.0_L64_Nc3_big_ens.dat', dtype=np.complex128).reshape(-1, 64, 64, 3)[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb1ca8-eeea-47a4-b6d5-9c311b249764",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "axes[0].imshow(np.angle(ens[-1,:,:,1]/ens[-1,:,:,2]), cmap='twilight', interpolation='nearest')\n",
    "axes[1].imshow(np.angle(ens[-5,:,:,1]/ens[-5,:,:,2]), cmap='twilight', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9192dba-6507-4757-aeac-8b8ab7abd6e2",
   "metadata": {},
   "source": [
    "Action defined by:\n",
    "$$\n",
    "S(z) = -\\beta \\sum_{i,\\mu} |z_i z^\\dagger_{i+\\hat{\\mu}}|^2 = -\\beta \\sum_{i,\\mu} (z_i z^\\dagger_{i+\\hat\\mu}) (z_{i+\\hat\\mu} z^\\dagger_i)\n",
    "$$\n",
    "Force is then:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial X^R_i} S(z) = -2 \\beta \\, \\mathrm{Re} \\sum_{\\mu} (z^\\dagger_{i+\\hat\\mu} (z_{i+\\hat\\mu} z^\\dagger_i) + z_{i-\\hat\\mu}),\n",
    "\\qquad\n",
    "\\frac{\\partial}{\\partial X^I_i} S(z) = -2 \\beta \\, \\mathrm{Re} \\sum_{\\mu} (z_{i+\\hat\\mu} + z_{i-\\hat\\mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9af7ef-1900-401c-8f28-52990714fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_torch = torch.tensor(ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0b8b9-c867-4958-b120-60e7723f28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_complex(x):\n",
    "    XR = x[...,::2]\n",
    "    XI = x[...,1::2]\n",
    "    z = XR + 1j*XI\n",
    "    zbar = XR - 1j*XI\n",
    "    return z, zbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e7531-b938-4f95-8dc5-67a59cab0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_real(z):\n",
    "    return torch.stack([z.real, z.imag], axis=-1).flatten(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ac9c4-215e-41bb-adaa-a7c69dd19aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(z, zbar, *, beta):\n",
    "    assert len(z.shape) == 4, 'z must have shape (batch, Lx, Lt, Nc)'\n",
    "    assert z.shape == zbar.shape\n",
    "    S = torch.zeros(z.shape[0])\n",
    "    for mu in range(2):\n",
    "        h1 = torch.sum(z * torch.roll(zbar, -1, dims=mu+1), axis=-1)\n",
    "        h2 = torch.sum(zbar * torch.roll(z, -1, dims=mu+1), axis=-1)\n",
    "        S = S + torch.sum(1.0 - h1*h2, axis=(1,2))\n",
    "    return beta * S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f5ef6-0e1c-46f2-b2c3-77b62388bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_action(x, *, beta):\n",
    "    assert len(x.shape) == 4, 'x must have shape (batch, Lx, Lt, 2*Nc)'\n",
    "    # F = np.zeros(x.shape)\n",
    "    # for mu in range(2):\n",
    "    #     F -= 2 * torch.sum(z * torch.roll(z.conj(), -1, axis=mu+1), axis=-1)\n",
    "    # return beta * F\n",
    "    def _single_action(x):\n",
    "        z = (x[...,::2] + 1j*x[...,1::2])[None]\n",
    "        zbar = (x[...,::2] - 1j*x[...,1::2])[None]\n",
    "        return action(z, zbar, beta=beta)[0].real\n",
    "    return torch.func.vmap(torch.func.jacrev(_single_action))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9373e-9f46-477a-a1f5-8498cd1ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "E = action(ens, np.conj(ens), beta=1.0) / (ens.shape[-2]*ens.shape[-3])\n",
    "E_est = al.bootstrap(al.bin_data(E, binsize=100)[1], Nboot=1000, f=al.rmean)\n",
    "ax.plot(E)\n",
    "ax.fill_between(\n",
    "    [0, len(E)], [E_est[0]-E_est[1]]*2, [E_est[0]+E_est[1]]*2,\n",
    "    ec='none', color='xkcd:red', alpha=0.5, zorder=2,\n",
    "    label=rf'${E_est[0]:.3f} \\pm {E_est[1]:.3f}$')\n",
    "ax.legend()\n",
    "ax.set_xlabel('mc step')\n",
    "ax.set_ylabel('$E$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15de51-6630-4796-8327-42f497339d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pij_est = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        Pij = np.mean(ens[...,i]*np.conj(ens[...,j]), axis=(-1,-2))\n",
    "        Pij_est.append(al.bootstrap(al.bin_data(Pij, binsize=250)[1], Nboot=1000, f=al.rmean))\n",
    "        print(f'{i=} {j=} {Pij_est[-1]=}')\n",
    "Pij_est = np.stack(Pij_est, axis=-1)\n",
    "print(f'{Pij_est.shape=}')\n",
    "fig, ax = plt.subplots(1,1)\n",
    "al.add_errorbar(Pij_est, ax=ax, marker='o', linestyle='', capsize=2, fillstyle='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5a07b-2339-4668-b1b7-08fe363cef37",
   "metadata": {},
   "source": [
    "# PINN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63d1b1-3536-415c-ac45-9b53ada199ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_jac(x: torch.Tensor):\n",
    "    n_dim = len(x.shape[1:])\n",
    "    d = functools.reduce(op.mul, x.shape[1:1+n_dim//2])\n",
    "    return x.reshape(-1, d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619ad8b-f776-433e-9f12-64cf168d87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, Nc, hidden_ch=8):\n",
    "        super().__init__()\n",
    "        self.in_ch = 2*Nc\n",
    "        self.out_ch = 2*Nc\n",
    "        # just a crappy conv net\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.in_ch, hidden_ch, 3, padding=1, padding_mode='circular'),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(hidden_ch, hidden_ch, 3, padding=1, padding_mode='circular'),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(hidden_ch, self.out_ch, 3, padding=1, padding_mode='circular'),\n",
    "        )\n",
    "\n",
    "    def _vel_single(self, x):\n",
    "        f = self.net(x)\n",
    "        fx = torch.sum(f*x)\n",
    "        return f - fx*x\n",
    "\n",
    "    def forward(self, x):\n",
    "        funcF = torch.func.vmap(self._vel_single)\n",
    "        # F = funcF(x)\n",
    "        # jacF = torch.func.vmap(torch.func.jacfwd(self._vel_single))(x)\n",
    "        # jacF = reshape_jac(jacF)\n",
    "        # divF = torch.einsum('xii->x', jacF)\n",
    "        # hutch estimator\n",
    "        eta = torch.randn_like(x)\n",
    "        F, jvp = torch.func.jvp(funcF, (x,), (eta,))\n",
    "        inds = tuple(range(1, len(F.shape)))\n",
    "        divF = (eta*jvp).sum(inds)\n",
    "        # divF = torch.zeros(F.shape[0]).to(device=F.device)\n",
    "        return F, divF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e7fe8-9fa9-4e03-a81e-8e166f9cb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, gradS, Q, model, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    F, divF = model(x)\n",
    "    inds = tuple(range(1, len(F.shape)))\n",
    "    FgradS = (F*gradS).sum(inds)\n",
    "    assert divF.shape == FgradS.shape\n",
    "    assert divF.shape == Q.shape, f'{divF.shape=} {Q.shape=}'\n",
    "    # NOTE: assumes either on-policy training or <Q> = 0\n",
    "    loss = ((divF - FgradS - Q)**2).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return dict(loss=grab(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93eb14-7354-4349-a7fe-9678aa9008db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ens, beta, *, i=0, j=1, batch_size, n_step):\n",
    "    ens = to_real(ens).to(torch.float32)\n",
    "    gradS = grad_action(ens, beta=beta)\n",
    "    Q = torch.mean(ens[...,0,i]*ens[...,0,j].conj(), axis=-1).real\n",
    "    # TEST\n",
    "    Q_est = al.bootstrap(grab(Q), Nboot=1000, f=al.rmean)\n",
    "    print(f'{Q_est=}')\n",
    "    Nc = ens.shape[-1]//2\n",
    "    # move channels dim\n",
    "    gradS = gradS.moveaxis(-1, 1)\n",
    "    ens = ens.moveaxis(-1, 1)\n",
    "    model = Model(Nc).to(train_device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    hist = dict(loss=[])\n",
    "    for i in range(n_step):\n",
    "        inds = np.random.randint(len(ens), size=batch_size)\n",
    "        xi = ens[inds].to(train_device)\n",
    "        gradSi = gradS[inds].to(train_device)\n",
    "        Qi = Q[inds].to(train_device)\n",
    "        res = train_step(xi, gradSi, Qi, model, optimizer)\n",
    "        hist['loss'].append(res['loss'])\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'Step {i+1}: Loss {res[\"loss\"]:.2g}')\n",
    "    for k in hist:\n",
    "        hist[k] = np.stack(hist[k])\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(hist['loss'])\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Train step')\n",
    "    ax.set_yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1878f5-0eff-47b9-82ff-a12f6b4d5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ens_torch, beta=4.0, batch_size=32, n_step=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55c9a6-19f2-494e-86fd-68e30d9155b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
